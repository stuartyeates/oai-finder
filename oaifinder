#!/bin/bash
#a daemon for finding OAI servers on the internet
set -x # turn on debugging
#set -e # exit bas on first uncaught error

DAEMONNAME="oaifinder"

PREFIX=$PWD/oaifinder-files/
DATADIR=${PREFIX}/var/lib/${DAEMONNAME}
CACHEDIR=${DATADIR}/cache
CONFIGDIR=${PREFIX}/etc/${DAEMONNAME}
LOGDIR=${PREFIX}/var/log/${DAEMONNAME}

URLLOG=${LOGDIR}/urls-$(date -d "today" +"%Y%m%d")
LOG=${LOGDIR}/oaifinder-$(date -d "today" +"%Y%m%d").log

yell() { echo "$0: $*" >&2; }
die() { yell "$*"; exit 111; }

# if there's a local config file, source it 
if [ ! -d "${CONFIGDIR}" ]; then
    mkdir -p "${CONFIGDIR}" || die "cannot create ${CONFIGDIR}"
fi
if [  -e "${CONFIGDIR}/${DAEMONNAME}.conf" ]; then
   source  "${CONFIGDIR}/${DAEMONNAME}.conf" 
fi

# make sure the other directories exis
if [ ! -d "${DATADIR}" ]; then
    mkdir -p "${DATADIR}" || die "cannot create ${DATADIR}"
fi
if [ ! -d "${LOGDIR}" ]; then
    mkdir -p "${LOGDIR}" || die "cannot create ${LOGDIR}"
fi
if [ ! -d "${CACHEDIR}" ]; then
    mkdir -p "${CACHEDIR}" || die "cannot create ${CACHEDIR}"
fi

#create a random tmp directory for this instance of the script.
mkdir -p ${PREFIX}/tmp/
TMPDIR=`mktemp -d ${PREFIX}/tmp/tmp.XXXXXXX` || die "cannot create TMPDIR"
mkdir -p ${TMPDIR}

GUESSES=${TMPDIR}/guesses
EXPLORE=${TMPDIR}/explore



#max temp size in bytes 
MAXTMPSIZE=32000000
# are we accessing the search engine
DOSEARCH="true"
# are we checking urls
DOCHECK="true"

# seconds to pause for at startup before starting work
STARTUPPAUSE=12
# pause between searches
CYCLEPAUSE=6
# pause between pages in a search
SEARCHPAUSE=10


#perform startup activities
###########################
sleep ${STARTUPPAUSE}


#load normally cached files
###########################

load_cached_files () {

    if [ ! -f "${CACHEDIR}/en-subjects-wordlist" ]; then
	curl "http://en.wikipedia.org/wiki/Outline_of_academic_disciplines"  --output "${CACHEDIR}/en-subjects"
	cat "${CACHEDIR}/en-subjects" | sed 's|<[^>]*>||g' |tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012' | tr "'" "\012" |  tr 'A-Z'  'a-z' |  sort | uniq | grep -v '[0-9]' | grep '....' >  "${CACHEDIR}/en-subjects-wordlist"
    fi
    
    if [ ! -f "${CACHEDIR}/fr-subjects-wordlist" ]; then
	curl "http://fr.wikipedia.org/wiki/Liste_des_disciplines_scientifiques"  --output "${CACHEDIR}/fr-subjects"
	cat "${CACHEDIR}/fr-subjects" | sed 's|<[^>]*>||g' |tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012'| tr '[:punct:][:space:][:digit:][:cntrl:]' '\012' | tr "'" "\012" |  tr 'A-Z' 'a-z' |  sort | uniq | grep -v '[0-9]' | grep '....' | grep -F -x -v -f "${CACHEDIR}/en-subjects-wordlist" >  "${CACHEDIR}/fr-subjects-wordlist"
    fi
    
    if [ ! -f "${CACHEDIR}/ar-subjects-wordlist" ]; then
	curl "http://ar.wikipedia.org/wiki/%D9%85%D9%84%D8%AD%D9%82:%D9%82%D8%A7%D8%A6%D9%85%D8%A9_%D8%A7%D9%84%D8%AA%D8%AE%D8%B5%D8%B5%D8%A7%D8%AA_%D8%A7%D9%84%D8%A3%D9%83%D8%A7%D8%AF%D9%8A%D9%85%D9%8A%D8%A9"  --output "${CACHEDIR}/ar-subjects"
	cat "${CACHEDIR}/ar-subjects" | sed 's|<[^>]*>||g' |tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012' | tr '[:punct:][:space:][:digit:][:cntrl:]' '\012' |tr "'" "\012" |  tr 'A-Z' 'a-z' |  sort | uniq | grep -v '[0-9]' | grep '....' | grep -F -x -v -f "${CACHEDIR}/en-subjects-wordlist">  "${CACHEDIR}/ar-subjects-wordlist"
    fi
    
    if [ ! -f "${CACHEDIR}/ja-subjects-wordlist" ]; then
	curl "http://ja.wikipedia.org/wiki/%E5%AD%A6%E5%95%8F%E3%81%AE%E4%B8%80%E8%A6%A7"  --output "${CACHEDIR}/ja-subjects"
	cat "${CACHEDIR}/ja-subjects" | sed 's|<[^>]*>||g' | tr '[:punct:][:space:][:digit:][:cntrl:]' '\012' | tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012' | tr "'" "\012" |  tr 'A-Z' 'a-z' |  sort | uniq | grep -v '[0-9]' | grep '..' | grep -F -x -v -f "${CACHEDIR}/en-subjects-wordlist">  "${CACHEDIR}/ja-subjects-wordlist"
    fi
    
    if [ ! -f "${CACHEDIR}/zh-subjects-wordlist" ]; then
	curl "http://zh.wikipedia.org/wiki/%E5%AD%B8%E7%A7%91%E5%88%97%E8%A1%A8"  --output "${CACHEDIR}/zh-subjects"
	cat "${CACHEDIR}/zh-subjects" | sed 's|<script>[^<]*</script>||g' | sed 's|<[^>]*>||g' | tr '[:punct:][:space:][:digit:][:cntrl:]' '\012' | tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012' | tr "'" "\012" |  tr 'A-Z' 'a-z' |  sort | uniq | grep -v '[0-9]' | grep '..' | grep -F -x -v -f "${CACHEDIR}/en-subjects-wordlist">  "${CACHEDIR}/zh-subjects-wordlist"
    fi
    
    if [ ! -f "${CACHEDIR}/pt-subjects-wordlist" ]; then
	curl "http://pt.wikipedia.org/wiki/Lista_de_disciplinas_acad%C3%AAmicas"  --output "${CACHEDIR}/pt-subjects"
	cat "${CACHEDIR}/pt-subjects" | tr '\012' ' ' | sed 's|<[^>]*>||g' | tr '[:punct:][:space:][:digit:][:cntrl:]' '\012' | tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012' | tr "'" "\012" |  tr 'A-Z' 'a-z' |  sort | uniq | grep -v '[0-9]' | grep '..' | grep -F -x -v -f "${CACHEDIR}/en-subjects-wordlist" >  "${CACHEDIR}/pt-subjects-wordlist"
    fi
    
    if [ ! -f "${CACHEDIR}/tl-subjects-wordlist" ]; then
    curl "http://tl.wikipedia.org/wiki/Talaan_ng_mga_disiplinang_pang-akademiya"  --output "${CACHEDIR}/tl-subjects"
    cat "${CACHEDIR}/tl-subjects" | sed 's|<[^>]*>||g' | tr '[:punct:][:space:][:digit:][:cntrl:]' '\012' | tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012' | tr "'" "\012" |  tr 'A-Z' 'a-z' |  sort | uniq | grep -v '[0-9]' | grep '..' | grep -F -x -v -f "${CACHEDIR}/en-subjects-wordlist" >  "${CACHEDIR}/tl-subjects-wordlist"
    fi
    
    if [ ! -f "${CACHEDIR}/es-subjects-wordlist" ]; then
	curl "http://es.wikipedia.org/wiki/Anexo:Disciplinas_acad%C3%A9micas"  --output "${CACHEDIR}/es-subjects"
	cat "${CACHEDIR}/es-subjects" | sed 's|<[^>]*>||g' | tr '[:punct:][:space:][:digit:][:cntrl:]' '\012' | tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012' | tr "'" "\012" |  tr 'A-Z' 'a-z' |  sort | uniq | grep -v '[0-9]' | grep '..' | grep -F -x -v -f "${CACHEDIR}/en-subjects-wordlist" >  "${CACHEDIR}/es-subjects-wordlist"
    fi
    
    if [ ! -f "${CACHEDIR}/country-names-wordlist" ]; then
	curl "http://en.wikipedia.org/wiki/List_of_countries_and_dependencies_and_their_capitals_in_native_languages"  --output - > "${CACHEDIR}/country-names"
	curl "http://en.wikipedia.org/wiki/List_of_adjectivals_and_demonyms_for_subcontinental_regions"  --output - >> "${CACHEDIR}/country-names"
	curl "http://en.wikipedia.org/wiki/List_of_adjectival_and_demonymic_forms_for_countries_and_nations"  --output - >> "${CACHEDIR}/country-names"
	curl "http://en.wikipedia.org/wiki/List_of_Latin_names_of_regions"  --output - >> "${CACHEDIR}/country-names"
	curl "http://en.wikipedia.org/wiki/List_of_official_languages_by_state"  --output - >> "${CACHEDIR}/country-names"
	curl "http://en.wikipedia.org/wiki/List_of_largest_languages_without_official_status"  --output - >> "${CACHEDIR}/country-names"
	cat "${CACHEDIR}/country-names" | sed 's|<script>[^<]*</script>||g' | sed 's|<[^>]*>||g' | tr '[:punct:][:space:][:digit:][:cntrl:]' '\012' | tr ' -"()\[\],.?!:\t|^<>/*;$\\{}' '\012' | tr "'" "\012" |  tr 'A-Z' 'a-z' |  sort | uniq | grep -v '[0-9]' | grep '..' | grep -F -x -v -f "${CACHEDIR}/en-subjects-wordlist" >  "${CACHEDIR}/country-names-wordlist"
    fi
}

SEARCHURL_0=
SEARCHURL_1=
SEARCHURL_2=
SEARCHURL_3=
SEARCHURL_4=
SEARCHURL_5=
SEARCHURL_6=
SEARCHURL_7=
SEARCHURL_8=
SEARCHURL_9=
SEARCHURL_10=
SEARCHURL_11=
SEARCHURL_12=
SEARCHURL_13=
SEARCHURL_14=
SEARCHURL_15=
SEARCHURL_16=
SEARCHURL_17=
SEARCHURL_18=
SEARCHURL_19=

# call with 1-4 args to compose and populate search urls
pop_search_urls_google () {
    BASEURL="uninitialised"
    
    if [  "$1" ]
    then
	if [  "$2" ]
	then
	    if [  "$3" ]
	    then
		if [  "$4" ]
		then
		    BASEURL="http://www.google.co.nz/search?q=${1}+${2}+${3}+${4}+filetype:html&filter=0&num=50"
		else
		    BASEURL="http://www.google.co.nz/search?q=${1}+${2}+${3}+filetype:html&filter=0&num=50"
		fi
	    else
		BASEURL="http://www.google.co.nz/search?q=${1}+${2}+filetype:html&filter=0&num=50"
	    fi
	else
	    BASEURL="http://www.google.co.nz/search?q=${1}+filetype:html&filter=0&num=50"
	fi
    else
	die "Error: pop_search_urls_google called with inappropiate args"
    fi
    
    counter=0
    for n in 0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 ; do
	NAME=SEARCHURL_${counter}
	export SEARCHURL_${counter}="${BASEURL}&start=${n}"
	((counter++))
    done
    
    return 0;
}

do_search () {
    TMPFILE=`mktemp ${TMPDIR}/urls.XXXXXXXXXX` || die "unable to create temporary file"

    for n in 0 1; do
#    for n in 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ; do
	URL="SEARCHURL_${n}"
	curl "${!URL}" -s  --user-agent "Mozilla/4.0" |   tr '"<>()%, ' '\012' | tr "'" '\012' | sed 's/http/\nhttp/g' | sed 's/&amp;/\n&amp;/g' | sed 's/+.*//g' | sed 's/=related:/\n/g' | grep '^\(http\|[a-z]+\.[a-z]+/\)' | sort | uniq >> ${TMPFILE}
	sleep ${SEARCHPAUSE}
    done
}

load_cached_files

do_winnow_urls () {
    touch ${DATADIR}/urls_tried
    cat ${TMPDIR}/urls.* | grep -Ev 'google.com|msn.com|ae.webradar.me|ameinfo.com|arab.jinbo.net|sogou.com|live.com|googleusercontent.com|google.|blogspot.' > ${TMPDIR}/candidates
    comm -1 ${DATADIR}/urls_tried  ${TMPDIR}/candidates >  ${TMPDIR}/successful_candidates
}


do_dowse () {

    
    for url in `cat  ${TMPDIR}/successful_candidates | sed 's/\&.*//' | sed 's/\?.*//' | grep -v '.jpg$' | grep -v '.gif$'| grep -v '.png$' |grep -v blogspot | sort | uniq`; do 
	
        #basic OAI options:
	if [[ ${url} == *verb\=Identify ]];  
	then
	    echo "${url}" >>  ${GUESSES}
	elif [[ ${url} == */oai ]]; 
	then
	    echo "${url}?verb=Identify" >>  ${GUESSES}
	    echo "${url}/request?verb=Identify" >>  ${GUESSES}
	fi
	
    # OJS options
	if [[ ${url} == */oai/request ]]
	then
	    echo "${url}?verb=Identify" >>  ${GUESSES}
	elif [[ ${url} =~ /index.php/[^/]+/journal= ]]
	then
	    echo OJSRAW  ${url} | sed 's|\(/index.php/[^/]*/\)journal=\([^\&]\)|\1?journal=\1\&page=oai?verb=Identify|' 
	    echo ${url} | sed 's|\(/index.php/[^/]*/\)journal=\([^\&]\)|\1?journal=\1\&page=oai?verb=Identify|' >>   ${GUESSES}
	    echo ${url} | sed 's|\(/index.php/\).*|\1|' >>  ${EXPLORE}
	elif [[ ${url} =~ /lib/pkp/ ]]
	then
	    echo ${url} | sed 's|lib/pkp/.*||' >>  ${EXPLORE}
	elif [[ ${url} =~ /public/journal ]]
	then
	    echo ${url} | sed 's|public/journal.*||' >>   ${EXPLORE}
	elif [[ ${url} =~ plugins/themes ]]
	then
	    echo ${url} | sed 's|plugins/themes.*||' >>   ${EXPLORE}
	elif [[ ${url} =~ /article/view ]]
	then
	    echo ${url} | sed 's|/article/view.*|/oai?verb=Identify|' >>    ${GUESSES}
	elif [[ ${url} =~ /issue/archive ]]
	then
	    echo ${url} | sed 's|/issue/archive.*|/oai?verb=Identify|' >>    ${GUESSES}
	elif [[ ${url} =~ /article/view ]]
	then
	    echo ${url} | sed 's|/article/view.*|/oai?verb=Identify|' >>    ${GUESSES}
	elif [[ ${url} =~ /styles/rightSidebar.css ]]
	then
	    echo ${url} | sed 's|styles/rightSidebar.css.*||' >>    ${EXPLORE}
	elif [[ ${url} =~ gateway/plugin/WebFeedGatewayPlugin ]]
	then
	    echo ${url} | sed 's|gateway/plugin/WebFeedGatewayPlugin.*||' >>    ${EXPLORE}
	elif [[ ${url} =~ /index.php  ]]
	then
	    echo ${url} | sed 's|\(/index.php\).*|\1/oai?verb=Identify|' >>   ${GUESSES}
	    echo ${url} | sed 's|\(/index.php\).*|\1|' >>  ${EXPLORE}
	elif [[ ${url} =~ ojs ]]
	then
	    echo ${url} | sed 's|\(ojs\).*|\1|' >>   ${EXPLORE}
	    
    #Greenstone options
	elif [[ ${url} =~ /cgi-bin/ ]]
	then
	    echo ${url}
	    echo GSDL ${url} | sed 's|\(.*/cgi-bin\).*|\1/oaiserver.cgi?verb=Identify|'
	    echo GSDL ${url} | sed 's|\(.*/cgi-bin\).*|\1/oaiserver?verb=Identify|'
	    echo ${url} | sed 's|\(.*/cgi-bin\).*|\1/oaiserver.cgi?verb=Identify|' >>   ${GUESSES}
	    echo ${url} | sed 's|\(.*/cgi-bin\).*|\1/oaiserver?verb=Identify|' >>   ${GUESSES}
	    
	elif [[ ${url} =~ /gsdl/ ]]
	then
	    echo ${url}
	    echo GSDL ${url} | sed 's|\(.*/gsdl\).*|\1/cgi-bin/oaiserver.cgi?verb=Identify|'
	    echo GSDL ${url} | sed 's|\(.*/gsdl\).*|\1/cgi-bin/oaiserver?verb=Identify|'
	    echo ${url} | sed 's|\(.*/gsdl\).*|\1/cgi-bin/oaiserver.cgi?verb=Identify|' >>   ${GUESSES}
	    echo ${url} | sed 's|\(.*/gsdl\).*|\1/cgi-bin/oaiserver?verb=Identify|' >>   ${GUESSES}
	    
	    
        #dspace options
	elif [[ ${url} =~ /handle/[0-9]+/[0-9] || ${url} =~ /xmlui || ${url} =~ /advanced-search || ${url} =~ /community-list || ${url} =~ /jspui || ${url} =~ .*/browse.* ]]
	then
	    echo ${url}
	    echo DSPACE ${url} | sed 's@/\(handle\|xmlui\|advanced-search\|community-list\|browse\|jspui\).*@/oai/request?verb=Identify@'
	    echo DSPACE ${url} | sed 's@/\(handle\|xmlui\|advanced-search\|community-list\|browse\|jspui\).*@/dspace-oai/request?verb=Identify@'
	    echo ${url} | sed 's@/\(handle\|xmlui\|advanced-search\|community-list\|browse\|jspui\).*@/oai/request?verb=Identify@' >>   ${GUESSES}
	    echo ${url} | sed 's@/\(handle\|xmlui\|advanced-search\|community-list\|browse\|jspui\).*@/dspace-oai/request?verb=Identify@' >>   ${GUESSES}
	    
        #vital options
	elif [[ ${url} =~ /vital/ ]]
	then
	    echo ${url}
	    echo VITAL ${url} | sed 's|\(/vital\).*|\1/oai/provider?verb=Identify|'
	    echo ${url} | sed 's|\(/vital\).*|\1/oai/provider?verb=Identify|' >>   ${GUESSES}
	    
        #etd-db options
	elif [[ ${url} =~  /etd-db/  ]]
	then
	    echo ${url}
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/NDLTD-OAI/oai.pl?verb=Identify|'
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/ETD-oai/oai.pl?verb=Identify|'
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/oai/oai.pl?verb=Identify|'
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/OAI/oai.pl?verb=Identify|'
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/etddb/oai.pl?verb=Identify|'
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/ETD-OAI/etddb/oai.pl?verb=Identify|'
	    
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/NDLTD-OAI/oai.pl?verb=Identify|' >>   ${GUESSES}
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/ETD-oai/oai.pl?verb=Identify|' >>   ${GUESSES}
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/oai/oai.pl?verb=Identify|' >>   ${GUESSES}
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/OAI/oai.pl?verb=Identify|' >>   ${GUESSES}
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/etddb/oai.pl?verb=Identify|' >>   ${GUESSES}
	    echo VITAL ${url} | sed 's|\(/[Ee][Tt][dD]-[Dd][Bb]\).*|\1/ETD-OAI/etddb/oai.pl?verb=Identify|' >>   ${GUESSES}

        #eprints options
        #Im struggling to find eprint-specific URL patterns
        # policy.html
        # perl/users/home" /cgi/latest_tool?output=RSS2 /cgi/oai2
	    
	else
	    echo UNCLAIMED: ${url}
	    echo ${url} >> ${UNCLAIMED}
	    if [[ 1 == 1 ]]; 
	    then
		base=`echo  ${url} | sed 's|/[^/]*$|/|' | sed 's|\?.*||'`
		echo BASE ${base}
		while [[  $base =~ http://[^/]+/.* ]]; do	    
		    echo BASE ${base}
		    echo GUESS ${base} | sed 's|$|?verb=Identify|'
		    echo ${base} | sed 's|$|?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|/?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|oai?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|oai2?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|oai.php?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|oai2.php?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|OAI2.0?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|cgi/oai2?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|perl/oai2?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|OAI?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|servlets/OAIDataProvider?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|oaiprovider?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|provider?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|oai.aspx?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|sobekcm_oai.aspx?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|oai2d.py/?verb=Identify|' >>   ${GUESSES}
		    echo ${base} | sed 's|$|infolib/oai_repository/repository?verb=Identify|' >>   ${GUESSES}
		    
		    newbase=`echo  ${base} | sed 's|/[^/]*/$|/|'`
		    base=$newbase
		done
	    fi
	    echo done

	fi
    done
}


do_download () {

    touch ${DATADIR}/urls_downloaded
    for url in `comm -1 ${DATADIR}/urls_downloaded ${GUESSES} | sort | uniq`; do 
	#RESULT=`curl --silent  "${url}" `
	RETURNVALUE=$?
	
	echo ${RETURNVALUE} ${url}
	echo ${url} >>  ${DATADIR}/urls_downloaded
    done

}

do_check_urls () {
    do_winnow_urls 
    do_dowse
    do_download

}

while true; do

    if [ "$DOSEARCH" ]; then
	#first we query the search engines...
	for term in `cat search-terms/*.utf8|  grep '.'| sort | uniq| shuf | head -1`; do 
	    pop_search_urls_google "${term}"
	    do_search
	    
	    for word1 in `cat ${CACHEDIR}/*-wordlist| grep '.' | sort | uniq | shuf | head -2`; do 
		pop_search_urls_google "${term}" "${word1}"
		do_search
		
		for word2 in `cat ${CACHEDIR}/*-wordlist| grep '.' | sort | uniq | shuf | head -1`; do 
		    pop_search_urls_google "${term}" "${word2}"
		    do_search

		    pop_search_urls_google "${term}" "${word1}" "${word2}"
		    do_search
		done
	    done
	done

	cat "${TMPDIR}"/urls.* | sort | uniq >> ${URLLOG}
#	rm "${TMPDIR}"/urls.*
    fi
    
    if [ "$DOCHECK" ]; then
	echo doing the check
	do_check_urls
    fi
    
    sleep ${CYCLEPAUSE};
    exit 0
    
done